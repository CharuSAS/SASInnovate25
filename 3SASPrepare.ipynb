{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concatenate North American(exclude Alaska) and Mexican BumbleBee data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining tables in SAS is like worker bees stacking honeycombs‚Äîeach dataset adding its own golden sweetness. With SET statements or PROC APPEND, you can seamlessly merge observations into a thriving hive of insights. Let‚Äôs get buzzing! üêù"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know thy data using PROC CONTENTS. Before concatenating tables, first ensure that both datasets have the same structure (i.e., same variable names and types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2613055050.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    proc contents data=dst1;\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "proc contents data=dst1;\n",
    "run;\n",
    "proc contents data=dst2;\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the North American and Mexican Bumblebee data using the SET statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data dsconc;\n",
    "set dst1 dst2;\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did the concatenation fail?\n",
    "\n",
    "During the Access phase, we used PROC IMPORT to convert CSVs into SAS datasets. By default, PROC IMPORT \"guesses\" the data structure by examining the first 20 rows to determine variable types and lengths. It assigns the most prevalent data type (numeric or character) to each column. If most of the first 20 rows are missing, SAS defaults to the character data type, and any subsequent numeric values are set to missing. This is why the column occurenceID defined as Character in the Mexican bumblebee data conflicts with the numeric OccurenceId in the North American Bumblebee dataset.   The DATA step, however, offers more control, granularity, and precision for importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ata dst1;\n",
    "infile \"/workspaces/myfolder/SASPythonDataScientists/pattern_decline_N_American_Bumblebees.csv\"  dsd firstobs=2;\n",
    "input \n",
    "id \n",
    "institutionCode : $8. \n",
    "collectionCode : $4. \n",
    "basisOfRecord : $17.  \n",
    "occurrenceID :$9.\n",
    "catalognumber: $12. \n",
    "recordedBy $\n",
    "year\n",
    "month \n",
    "day \n",
    "country :$6. \n",
    "stateProvince  : $16.\n",
    "county : $17.\n",
    "locality  : $37. \n",
    "verbatimLatitude  \n",
    "verbatimLongitude \n",
    "identifiedBy : $18.\n",
    "scientificName  : $20. \n",
    "kingdom  : $8. \n",
    "phylum  : $10. \n",
    "class : $7. \n",
    "order  : $11. \n",
    "family  : $6. \n",
    "genus :  $6. \n",
    "specificEpithet : $13. \n",
    "scientificNameAuthorship : $13. \n",
    ";\n",
    "\n",
    "run;\n",
    "\n",
    "\n",
    "data dst2;\n",
    "infile \"/workspaces/myfolder/SASPythonDataScientists/pattern_decline_Mexican_Bumblebees.csv\"  dsd firstobs=2;\n",
    "input \n",
    "id \n",
    "institutionCode : $8. \n",
    "collectionCode : $4. \n",
    "basisOfRecord : $17.  \n",
    "occurrenceID :$9.\n",
    "catalognumber: $12. \n",
    "recordedBy $\n",
    "year\n",
    "month \n",
    "day \n",
    "country :$6. \n",
    "stateProvince  : $16.\n",
    "county : $17.\n",
    "locality  : $37. \n",
    "verbatimLatitude  \n",
    "verbatimLongitude \n",
    "identifiedBy : $18.\n",
    "scientificName  : $20. \n",
    "kingdom  : $8. \n",
    "phylum  : $10. \n",
    "class : $7. \n",
    "order  : $11. \n",
    "family  : $6. \n",
    "genus :  $6. \n",
    "specificEpithet : $13. \n",
    "scientificNameAuthorship : $13. \n",
    ";\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the metadata of the 2 tables, and pay careful attention to the offending type mismatch of the column OccurenceId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc contents data=dst1 varnum;\n",
    "run;\n",
    "proc contents data=dst2 varnum;\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now concatenate the 2 tables (filtering out Alaska from the North American Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data dsconc;\n",
    "set dst1(where=(country <> 'Alaska')) dst2;\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üêù Merging Datasets: A Bumble Bee Bonanza! üêù\n",
    "\n",
    "Just like bees waggle, not recite Latin, our data needs common names, not just Bombus jargon. So, we‚Äôll merge our North American & Mexican dataset with a lookup table‚Äîletting SAS do the heavy lifting while our data buzzes with clarity! üçØ‚ú® \n",
    "\n",
    "The term ‚Äúbumblebee‚Äù traces its roots to the word bumble, meaning to hum or buzz ‚Äî a fitting nod to the sound these vital pollinators make. Their scientific name, Bombus, was introduced in 1802 and is derived from Latin and Greek words for a buzzing sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc contents data=dsconc;\n",
    "run;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc contents data=dst3;\n",
    "run;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data dsmerge;\n",
    "    merge dsconc dst3;\n",
    "    by scientificname;\n",
    "run;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepping the datasets for merge by running a PROC SORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc sort data=dsconc;\n",
    "    by scientificname;\n",
    "run;\n",
    "proc sort data=dst3;\n",
    "by scientificname;\n",
    "run;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data dsmerge;\n",
    "    merge dsconc(in=inc) dst3(in=ind);\n",
    "    by scientificname;\n",
    "    if inc and ind;\n",
    "run;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc contents data=dsmerge;\n",
    "run;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
